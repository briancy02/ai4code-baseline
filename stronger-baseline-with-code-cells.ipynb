{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff9a319",
   "metadata": {
    "papermill": {
     "duration": 0.017954,
     "end_time": "2022-07-05T20:13:45.532680",
     "exception": false,
     "start_time": "2022-07-05T20:13:45.514726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a589c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:45.567534Z",
     "iopub.status.busy": "2022-07-05T20:13:45.566962Z",
     "iopub.status.idle": "2022-07-05T20:13:52.641910Z",
     "shell.execute_reply": "2022-07-05T20:13:52.641186Z"
    },
    "papermill": {
     "duration": 7.094496,
     "end_time": "2022-07-05T20:13:52.644048",
     "exception": false,
     "start_time": "2022-07-05T20:13:45.549552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.models.longformer.modeling_longformer import LongformerSelfAttention\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff48d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:52.679268Z",
     "iopub.status.busy": "2022-07-05T20:13:52.678902Z",
     "iopub.status.idle": "2022-07-05T20:13:52.779858Z",
     "shell.execute_reply": "2022-07-05T20:13:52.778546Z"
    },
    "papermill": {
     "duration": 0.120158,
     "end_time": "2022-07-05T20:13:52.781600",
     "exception": false,
     "start_time": "2022-07-05T20:13:52.661442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 64.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa50f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:52.818354Z",
     "iopub.status.busy": "2022-07-05T20:13:52.818152Z",
     "iopub.status.idle": "2022-07-05T20:13:52.836217Z",
     "shell.execute_reply": "2022-07-05T20:13:52.835550Z"
    },
    "papermill": {
     "duration": 0.038483,
     "end_time": "2022-07-05T20:13:52.838048",
     "exception": false,
     "start_time": "2022-07-05T20:13:52.799565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4119b998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:52.877570Z",
     "iopub.status.busy": "2022-07-05T20:13:52.877064Z",
     "iopub.status.idle": "2022-07-05T20:13:52.886450Z",
     "shell.execute_reply": "2022-07-05T20:13:52.885785Z"
    },
    "papermill": {
     "duration": 0.030985,
     "end_time": "2022-07-05T20:13:52.888200",
     "exception": false,
     "start_time": "2022-07-05T20:13:52.857215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555c9b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:52.924952Z",
     "iopub.status.busy": "2022-07-05T20:13:52.924568Z",
     "iopub.status.idle": "2022-07-05T20:13:52.938330Z",
     "shell.execute_reply": "2022-07-05T20:13:52.937477Z"
    },
    "papermill": {
     "duration": 0.034871,
     "end_time": "2022-07-05T20:13:52.940886",
     "exception": false,
     "start_time": "2022-07-05T20:13:52.906015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 741.80it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea496223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:13:52.982070Z",
     "iopub.status.busy": "2022-07-05T20:13:52.981857Z",
     "iopub.status.idle": "2022-07-05T20:14:32.575401Z",
     "shell.execute_reply": "2022-07-05T20:14:32.574601Z"
    },
    "papermill": {
     "duration": 39.61746,
     "end_time": "2022-07-05T20:14:32.577709",
     "exception": false,
     "start_time": "2022-07-05T20:13:52.960249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "python_files = sorted(Path('../input/codesearchnet/python/python/final/jsonl/train/').glob('**/*.jsonl'))\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "pydf = jsonl_list_to_dataframe(python_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef8d0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:14:32.616988Z",
     "iopub.status.busy": "2022-07-05T20:14:32.616283Z",
     "iopub.status.idle": "2022-07-05T20:14:32.642866Z",
     "shell.execute_reply": "2022-07-05T20:14:32.642250Z"
    },
    "papermill": {
     "duration": 0.047837,
     "end_time": "2022-07-05T20:14:32.644599",
     "exception": false,
     "start_time": "2022-07-05T20:14:32.596762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...</td>\n",
       "      <td>Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...</td>\n",
       "      <td>Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visually, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...</td>\n",
       "      <td>[def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....</td>\n",
       "      <td>Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...</td>\n",
       "      <td>[Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...</td>\n",
       "      <td>[def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...</td>\n",
       "      <td>Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...</td>\n",
       "      <td>[Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34</td>\n",
       "      <td>def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...</td>\n",
       "      <td>[def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...</td>\n",
       "      <td>Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73</td>\n",
       "      <td>def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...</td>\n",
       "      <td>[def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...</td>\n",
       "      <td>Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108</td>\n",
       "      <td>def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...</td>\n",
       "      <td>[def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...</td>\n",
       "      <td>Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...</td>\n",
       "      <td>[Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412178 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            repo                                    path  \\\n",
       "0      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "1      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "2      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "3      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "4      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "...                          ...                                     ...   \n",
       "29995       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29996       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29997       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29998       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29999       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "\n",
       "                                                                                                                           url  \\\n",
       "0      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "1      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "2      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "3      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "4      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "...                                                                                                                        ...   \n",
       "29995  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29996  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29997         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34   \n",
       "29998         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73   \n",
       "29999        https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108   \n",
       "\n",
       "                                                                                                                          code  \\\n",
       "0      def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...   \n",
       "1      def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...   \n",
       "2      def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...   \n",
       "3      def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...   \n",
       "4      def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...   \n",
       "...                                                                                                                        ...   \n",
       "29995  def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...   \n",
       "29996  def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...   \n",
       "29997  def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...   \n",
       "29998  def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...   \n",
       "29999  def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...   \n",
       "\n",
       "                                                                                                                   code_tokens  \\\n",
       "0      [def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...   \n",
       "1      [def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...   \n",
       "2      [def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...   \n",
       "3      [def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...   \n",
       "4      [def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...   \n",
       "...                                                                                                                        ...   \n",
       "29995  [def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....   \n",
       "29996  [def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...   \n",
       "29997  [def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...   \n",
       "29998  [def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...   \n",
       "29999  [def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...   \n",
       "\n",
       "                                                                                                                     docstring  \\\n",
       "0      Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...   \n",
       "1      Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...   \n",
       "2      Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...   \n",
       "3      Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...   \n",
       "4      Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...   \n",
       "...                                                                                                                        ...   \n",
       "29995  Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...   \n",
       "29996  Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...   \n",
       "29997  Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...   \n",
       "29998  Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...   \n",
       "29999  Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...   \n",
       "\n",
       "                                                                                                              docstring_tokens language partition  \n",
       "0                                                 [Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]   python     train  \n",
       "1                                                    [Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]   python     train  \n",
       "2                                                                        [Shows, the, face, recognition, results, visually, .]   python     train  \n",
       "3                             [Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]   python     train  \n",
       "4                [Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]   python     train  \n",
       "...                                                                                                                        ...      ...       ...  \n",
       "29995                                                 [Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]   python     train  \n",
       "29996  [Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...   python     train  \n",
       "29997             [Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]   python     train  \n",
       "29998  [Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...   python     train  \n",
       "29999  [Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...   python     train  \n",
       "\n",
       "[412178 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c72920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:14:32.684627Z",
     "iopub.status.busy": "2022-07-05T20:14:32.684434Z",
     "iopub.status.idle": "2022-07-05T20:14:33.497135Z",
     "shell.execute_reply": "2022-07-05T20:14:33.496271Z"
    },
    "papermill": {
     "duration": 0.835991,
     "end_time": "2022-07-05T20:14:33.500246",
     "exception": false,
     "start_time": "2022-07-05T20:14:32.664255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:00<00:00, 8058.65it/s]\n",
      "100%|██████████| 413/413 [00:00<00:00, 12189.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "def get_training_corpus():\n",
    "    to_return = [pydf[i : i + 1000][\"code\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))]\n",
    "    to_return.extend([pydf[i : i + 1000][\"docstring\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))])    \n",
    "    return to_return\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "\n",
    "training_corpus = get_training_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c60f7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:14:33.546732Z",
     "iopub.status.busy": "2022-07-05T20:14:33.546540Z",
     "iopub.status.idle": "2022-07-05T20:14:33.566995Z",
     "shell.execute_reply": "2022-07-05T20:14:33.566192Z"
    },
    "papermill": {
     "duration": 0.045667,
     "end_time": "2022-07-05T20:14:33.569194",
     "exception": false,
     "start_time": "2022-07-05T20:14:33.523527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "        \n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "        return x\n",
    "#         super(MarkdownModel, self).__init__()\n",
    "#         #self.max_input_len = 16384\n",
    "#         #self.max_input_len += 2\n",
    "#         self.attention_window = 256\n",
    "#         self.md_max_len = 64\n",
    "#         # lengthen model\n",
    "#         self.model = AutoModel.from_pretrained(model_path)\n",
    "#         longformer_model = LongformerModel.from_pretrained(\"../input/allenailongformerbase4096/longformer\")\n",
    "#         current_max_input_len, embed_size = self.model.embeddings.position_embeddings.weight.shape\n",
    "# #         print(current_max_input_len, embed_size)\n",
    "# #         new_encoder_pos_embed = self.model.embeddings.position_embeddings.weight.new_empty(self.max_input_len, embed_size)\n",
    "# #         k = 2\n",
    "# #         step = current_max_input_len - 2\n",
    "# #         while k < self.max_input_len - 1:\n",
    "# #             new_encoder_pos_embed[k:(k+step)] = self.model.embeddings.position_embeddings.weight[2:]\n",
    "# #             k += step\n",
    "# #         self.model.embeddings.position_embeddings.weight.data = new_encoder_pos_embed\n",
    "# #         print(self.model.embeddings.position_embeddings.weight.shape)\n",
    "        \n",
    "        \n",
    "#         #Attention set up\n",
    "#         self.model.config.attention_window = [self.attention_window] * self.model.config.num_hidden_layers\n",
    "#         #print(self.model.config.attention_window)\n",
    "#         self.model.config.attention_probs_dropout_prob = 0\n",
    "        \n",
    "#         for i, layer in enumerate(self.model.encoder.layer):\n",
    "#             longformer_self_attn_for_codebert = LongformerSelfAttention(self.model.config, layer_id=i)\n",
    "#             longformer_self_attn_for_codebert.query = layer.attention.self.query\n",
    "#             longformer_self_attn_for_codebert.key = layer.attention.self.key\n",
    "#             longformer_self_attn_for_codebert.value = layer.attention.self.value\n",
    "            \n",
    "#             longformer_self_attn_for_codebert.query_global = copy.deepcopy(layer.attention.self.query)\n",
    "#             longformer_self_attn_for_codebert.key_global = copy.deepcopy(layer.attention.self.key)\n",
    "#             longformer_self_attn_for_codebert.value_global = copy.deepcopy(layer.attention.self.value)\n",
    "            \n",
    "#             longformer_model.encoder.layer[i].attention.self = longformer_self_attn_for_codebert\n",
    "#         self.model = longformer_model\n",
    "#         self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        #global_attention_mask = torch.zeros_like(ids)\n",
    "        #global_attention_mask[:self.md_max_len] = 0\n",
    "        x = self.model(input_ids=ids, attention_mask=mask)[0]\n",
    "        #x = self.model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)[0]\n",
    "        #print(\"fts\", fts)\n",
    "        x = torch.cat((x[:, 0, :], fts), 1)\n",
    "        #print(\"/n\", x.size())\n",
    "        x = self.top(x)\n",
    "        return x\n",
    "        \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "        self.tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 50265)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=100,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e2898f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:14:33.614591Z",
     "iopub.status.busy": "2022-07-05T20:14:33.614296Z",
     "iopub.status.idle": "2022-07-05T20:19:35.055835Z",
     "shell.execute_reply": "2022-07-05T20:19:35.055083Z"
    },
    "papermill": {
     "duration": 301.466784,
     "end_time": "2022-07-05T20:19:35.058055",
     "exception": false,
     "start_time": "2022-07-05T20:14:33.591271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base\"\n",
    "BS = 32\n",
    "NW = 2\n",
    "test_df[\"pct_rank\"] = 0\n",
    "MAX_LEN = 64\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a56dfa72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:19:35.105830Z",
     "iopub.status.busy": "2022-07-05T20:19:35.105588Z",
     "iopub.status.idle": "2022-07-05T20:19:35.960892Z",
     "shell.execute_reply": "2022-07-05T20:19:35.959986Z"
    },
    "papermill": {
     "duration": 0.881296,
     "end_time": "2022-07-05T20:19:35.963175",
     "exception": false,
     "start_time": "2022-07-05T20:19:35.081879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d055574f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:19:36.012480Z",
     "iopub.status.busy": "2022-07-05T20:19:36.012240Z",
     "iopub.status.idle": "2022-07-05T20:19:36.020641Z",
     "shell.execute_reply": "2022-07-05T20:19:36.019958Z"
    },
    "papermill": {
     "duration": 0.036239,
     "end_time": "2022-07-05T20:19:36.023401",
     "exception": false,
     "start_time": "2022-07-05T20:19:35.987162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0,     7, 15872,  ...,     1,     1,     1],\n",
      "        [    0,   814, 42708,  ...,     1,     1,     1],\n",
      "        [    0,   814, 39153,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   814, 26936,  ...,   440,    12,  1926],\n",
      "        [    0,  4399,   551,  ...,   440,    12,  1926],\n",
      "        [    0,  4399,  1685,  ...,   440,    12,  1926]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88f7cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:19:36.072992Z",
     "iopub.status.busy": "2022-07-05T20:19:36.072443Z",
     "iopub.status.idle": "2022-07-05T20:19:36.084891Z",
     "shell.execute_reply": "2022-07-05T20:19:36.084119Z"
    },
    "papermill": {
     "duration": 0.038346,
     "end_time": "2022-07-05T20:19:36.086574",
     "exception": false,
     "start_time": "2022-07-05T20:19:36.048228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(tbar)):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    #model.load_state_dict(torch.load(ckpt_path))\n",
    "    state_dict = torch.load(ckpt_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    BS = 32\n",
    "    NW = 2\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    print(model)\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de166c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:19:36.134128Z",
     "iopub.status.busy": "2022-07-05T20:19:36.133640Z",
     "iopub.status.idle": "2022-07-05T20:25:01.634617Z",
     "shell.execute_reply": "2022-07-05T20:25:01.633758Z"
    },
    "papermill": {
     "duration": 325.528611,
     "end_time": "2022-07-05T20:25:01.638350",
     "exception": false,
     "start_time": "2022-07-05T20:19:36.109739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkdownModel(\n",
      "  (model): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:02,  2.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:02,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.05s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base/\"\n",
    "ckpt_path = \"../input/ai4code-models/model-4.bin\"\n",
    "y_test_1 = predict(model_path, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf4e053e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:25:01.702183Z",
     "iopub.status.busy": "2022-07-05T20:25:01.701954Z",
     "iopub.status.idle": "2022-07-05T20:25:01.707742Z",
     "shell.execute_reply": "2022-07-05T20:25:01.707024Z"
    },
    "papermill": {
     "duration": 0.03951,
     "end_time": "2022-07-05T20:25:01.709428",
     "exception": false,
     "start_time": "2022-07-05T20:25:01.669918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef060e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:25:01.771815Z",
     "iopub.status.busy": "2022-07-05T20:25:01.771381Z",
     "iopub.status.idle": "2022-07-05T20:25:01.786169Z",
     "shell.execute_reply": "2022-07-05T20:25:01.785457Z"
    },
    "papermill": {
     "duration": 0.047479,
     "end_time": "2022-07-05T20:25:01.787954",
     "exception": false,
     "start_time": "2022-07-05T20:25:01.740475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c c6cd22db 39e937ec 1372ae9b 0a226b6a 8cb8d28a e25aa9bd 90ed07ab f9893819 ba55e576 7f388a41 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 fe66203e 7844d5f8 5ce8863c 7f270e34 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 18ce8cc0 bd8fbd76 b78215d1 52fe98c4 0e2529e8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     ddfd239c c6cd22db 39e937ec 1372ae9b 0a226b6a 8cb8d28a e25aa9bd 90ed07ab f9893819 ba55e576 7f388a41 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                54c7cab3 fe66203e 7844d5f8 5ce8863c 7f270e34 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 18ce8cc0 bd8fbd76 b78215d1 52fe98c4 0e2529e8...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a0285b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T20:25:01.852016Z",
     "iopub.status.busy": "2022-07-05T20:25:01.851470Z",
     "iopub.status.idle": "2022-07-05T20:25:01.858356Z",
     "shell.execute_reply": "2022-07-05T20:25:01.857719Z"
    },
    "papermill": {
     "duration": 0.040309,
     "end_time": "2022-07-05T20:25:01.859978",
     "exception": false,
     "start_time": "2022-07-05T20:25:01.819669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36657cfe",
   "metadata": {
    "papermill": {
     "duration": 0.031272,
     "end_time": "2022-07-05T20:25:01.922176",
     "exception": false,
     "start_time": "2022-07-05T20:25:01.890904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 687.959783,
   "end_time": "2022-07-05T20:25:04.773710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-05T20:13:36.813927",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
