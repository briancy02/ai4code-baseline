{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f4fae3",
   "metadata": {
    "papermill": {
     "duration": 0.017594,
     "end_time": "2022-07-07T12:33:45.501704",
     "exception": false,
     "start_time": "2022-07-07T12:33:45.484110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c383c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:45.537370Z",
     "iopub.status.busy": "2022-07-07T12:33:45.536471Z",
     "iopub.status.idle": "2022-07-07T12:33:52.456757Z",
     "shell.execute_reply": "2022-07-07T12:33:52.456013Z"
    },
    "papermill": {
     "duration": 6.940833,
     "end_time": "2022-07-07T12:33:52.459139",
     "exception": false,
     "start_time": "2022-07-07T12:33:45.518306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.models.longformer.modeling_longformer import LongformerSelfAttention\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8794cdb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:52.495158Z",
     "iopub.status.busy": "2022-07-07T12:33:52.494298Z",
     "iopub.status.idle": "2022-07-07T12:33:52.576659Z",
     "shell.execute_reply": "2022-07-07T12:33:52.575927Z"
    },
    "papermill": {
     "duration": 0.102487,
     "end_time": "2022-07-07T12:33:52.578722",
     "exception": false,
     "start_time": "2022-07-07T12:33:52.476235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 94.02it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cecd185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:52.616714Z",
     "iopub.status.busy": "2022-07-07T12:33:52.616028Z",
     "iopub.status.idle": "2022-07-07T12:33:52.635778Z",
     "shell.execute_reply": "2022-07-07T12:33:52.635115Z"
    },
    "papermill": {
     "duration": 0.040642,
     "end_time": "2022-07-07T12:33:52.637978",
     "exception": false,
     "start_time": "2022-07-07T12:33:52.597336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6557d1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:52.676486Z",
     "iopub.status.busy": "2022-07-07T12:33:52.675799Z",
     "iopub.status.idle": "2022-07-07T12:33:52.686276Z",
     "shell.execute_reply": "2022-07-07T12:33:52.685415Z"
    },
    "papermill": {
     "duration": 0.03144,
     "end_time": "2022-07-07T12:33:52.688030",
     "exception": false,
     "start_time": "2022-07-07T12:33:52.656590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 30)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646eabbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:52.726338Z",
     "iopub.status.busy": "2022-07-07T12:33:52.724966Z",
     "iopub.status.idle": "2022-07-07T12:33:52.740693Z",
     "shell.execute_reply": "2022-07-07T12:33:52.739602Z"
    },
    "papermill": {
     "duration": 0.036672,
     "end_time": "2022-07-07T12:33:52.742455",
     "exception": false,
     "start_time": "2022-07-07T12:33:52.705783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 889.99it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc1f6d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:33:52.785022Z",
     "iopub.status.busy": "2022-07-07T12:33:52.784503Z",
     "iopub.status.idle": "2022-07-07T12:34:34.284000Z",
     "shell.execute_reply": "2022-07-07T12:34:34.283240Z"
    },
    "papermill": {
     "duration": 41.523784,
     "end_time": "2022-07-07T12:34:34.286576",
     "exception": false,
     "start_time": "2022-07-07T12:33:52.762792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "python_files = sorted(Path('../input/codesearchnet/python/python/final/jsonl/train/').glob('**/*.jsonl'))\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "pydf = jsonl_list_to_dataframe(python_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92503449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:34.325370Z",
     "iopub.status.busy": "2022-07-07T12:34:34.325155Z",
     "iopub.status.idle": "2022-07-07T12:34:34.352927Z",
     "shell.execute_reply": "2022-07-07T12:34:34.352263Z"
    },
    "papermill": {
     "duration": 0.049526,
     "end_time": "2022-07-07T12:34:34.355273",
     "exception": false,
     "start_time": "2022-07-07T12:34:34.305747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...</td>\n",
       "      <td>Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...</td>\n",
       "      <td>Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visually, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...</td>\n",
       "      <td>[def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....</td>\n",
       "      <td>Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...</td>\n",
       "      <td>[Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...</td>\n",
       "      <td>[def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...</td>\n",
       "      <td>Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...</td>\n",
       "      <td>[Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34</td>\n",
       "      <td>def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...</td>\n",
       "      <td>[def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...</td>\n",
       "      <td>Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73</td>\n",
       "      <td>def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...</td>\n",
       "      <td>[def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...</td>\n",
       "      <td>Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108</td>\n",
       "      <td>def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...</td>\n",
       "      <td>[def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...</td>\n",
       "      <td>Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...</td>\n",
       "      <td>[Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412178 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            repo                                    path  \\\n",
       "0      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "1      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "2      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "3      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "4      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "...                          ...                                     ...   \n",
       "29995       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29996       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29997       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29998       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29999       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "\n",
       "                                                                                                                           url  \\\n",
       "0      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "1      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "2      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "3      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "4      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "...                                                                                                                        ...   \n",
       "29995  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29996  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29997         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34   \n",
       "29998         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73   \n",
       "29999        https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108   \n",
       "\n",
       "                                                                                                                          code  \\\n",
       "0      def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...   \n",
       "1      def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...   \n",
       "2      def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...   \n",
       "3      def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...   \n",
       "4      def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...   \n",
       "...                                                                                                                        ...   \n",
       "29995  def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...   \n",
       "29996  def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...   \n",
       "29997  def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...   \n",
       "29998  def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...   \n",
       "29999  def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...   \n",
       "\n",
       "                                                                                                                   code_tokens  \\\n",
       "0      [def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...   \n",
       "1      [def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...   \n",
       "2      [def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...   \n",
       "3      [def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...   \n",
       "4      [def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...   \n",
       "...                                                                                                                        ...   \n",
       "29995  [def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....   \n",
       "29996  [def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...   \n",
       "29997  [def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...   \n",
       "29998  [def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...   \n",
       "29999  [def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...   \n",
       "\n",
       "                                                                                                                     docstring  \\\n",
       "0      Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...   \n",
       "1      Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...   \n",
       "2      Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...   \n",
       "3      Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...   \n",
       "4      Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...   \n",
       "...                                                                                                                        ...   \n",
       "29995  Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...   \n",
       "29996  Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...   \n",
       "29997  Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...   \n",
       "29998  Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...   \n",
       "29999  Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...   \n",
       "\n",
       "                                                                                                              docstring_tokens language partition  \n",
       "0                                                 [Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]   python     train  \n",
       "1                                                    [Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]   python     train  \n",
       "2                                                                        [Shows, the, face, recognition, results, visually, .]   python     train  \n",
       "3                             [Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]   python     train  \n",
       "4                [Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]   python     train  \n",
       "...                                                                                                                        ...      ...       ...  \n",
       "29995                                                 [Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]   python     train  \n",
       "29996  [Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...   python     train  \n",
       "29997             [Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]   python     train  \n",
       "29998  [Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...   python     train  \n",
       "29999  [Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...   python     train  \n",
       "\n",
       "[412178 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a2aa34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:34.396088Z",
     "iopub.status.busy": "2022-07-07T12:34:34.395834Z",
     "iopub.status.idle": "2022-07-07T12:34:35.087647Z",
     "shell.execute_reply": "2022-07-07T12:34:35.086859Z"
    },
    "papermill": {
     "duration": 0.715058,
     "end_time": "2022-07-07T12:34:35.090211",
     "exception": false,
     "start_time": "2022-07-07T12:34:34.375153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:00<00:00, 8607.10it/s]\n",
      "100%|██████████| 413/413 [00:00<00:00, 11051.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "def get_training_corpus():\n",
    "    to_return = [pydf[i : i + 1000][\"code\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))]\n",
    "    to_return.extend([pydf[i : i + 1000][\"docstring\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))])    \n",
    "    return to_return\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "\n",
    "training_corpus = get_training_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154996b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:35.136779Z",
     "iopub.status.busy": "2022-07-07T12:34:35.136082Z",
     "iopub.status.idle": "2022-07-07T12:34:35.162011Z",
     "shell.execute_reply": "2022-07-07T12:34:35.161190Z"
    },
    "papermill": {
     "duration": 0.050798,
     "end_time": "2022-07-07T12:34:35.163904",
     "exception": false,
     "start_time": "2022-07-07T12:34:35.113106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "#         super(MarkdownModel, self).__init__()\n",
    "#         self.model = AutoModel.from_pretrained(model_path)\n",
    "#         self.top = nn.Linear(769, 1)\n",
    "        \n",
    "#     def forward(self, ids, mask, fts):\n",
    "#         x = self.model(ids, mask)[0]\n",
    "#         x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "#         return x\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        #self.max_input_len = 16384\n",
    "        #self.max_input_len += 2\n",
    "        self.attention_window = 512\n",
    "        self.md_max_len = 64\n",
    "        # lengthen model\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        longformer_model = LongformerModel.from_pretrained(\"../input/allenailongformerbase4096/longformer\")\n",
    "        current_max_input_len, embed_size = self.model.embeddings.position_embeddings.weight.shape\n",
    "#         print(current_max_input_len, embed_size)\n",
    "#         new_encoder_pos_embed = self.model.embeddings.position_embeddings.weight.new_empty(self.max_input_len, embed_size)\n",
    "#         k = 2\n",
    "#         step = current_max_input_len - 2\n",
    "#         while k < self.max_input_len - 1:\n",
    "#             new_encoder_pos_embed[k:(k+step)] = self.model.embeddings.position_embeddings.weight[2:]\n",
    "#             k += step\n",
    "#         self.model.embeddings.position_embeddings.weight.data = new_encoder_pos_embed\n",
    "#         print(self.model.embeddings.position_embeddings.weight.shape)\n",
    "        \n",
    "        \n",
    "        #Attention set up\n",
    "        self.model.config.attention_window = [self.attention_window] * self.model.config.num_hidden_layers\n",
    "        self.model.config.attention_window[:4] = [32,32,32,32]\n",
    "        self.model.config.attention_window[4:6] = [64, 64]\n",
    "        self.model.config.attention_window[4:6] = [128,128]\n",
    "        self.model.config.attention_window[8:10] = [256, 256]\n",
    "        #print(self.model.config.attention_window)\n",
    "        self.model.config.attention_probs_dropout_prob = 0\n",
    "        \n",
    "        for i, layer in enumerate(self.model.encoder.layer):\n",
    "            longformer_self_attn_for_codebert = LongformerSelfAttention(self.model.config, layer_id=i)\n",
    "            longformer_self_attn_for_codebert.query = layer.attention.self.query\n",
    "            longformer_self_attn_for_codebert.key = layer.attention.self.key\n",
    "            longformer_self_attn_for_codebert.value = layer.attention.self.value\n",
    "            \n",
    "            longformer_self_attn_for_codebert.query_global = copy.deepcopy(layer.attention.self.query)\n",
    "            longformer_self_attn_for_codebert.key_global = copy.deepcopy(layer.attention.self.key)\n",
    "            longformer_self_attn_for_codebert.value_global = copy.deepcopy(layer.attention.self.value)\n",
    "            \n",
    "            longformer_model.encoder.layer[i].attention.self = longformer_self_attn_for_codebert\n",
    "        self.model = longformer_model\n",
    "        self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        global_attention_mask = torch.zeros_like(ids)\n",
    "        global_attention_mask[:self.md_max_len] = 0\n",
    "        #x = self.model(input_ids=ids, attention_mask=mask)[0]\n",
    "        x = self.model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)[0]\n",
    "        #print(\"fts\", fts)\n",
    "        x = torch.cat((x[:, 0, :], fts), 1)\n",
    "        #print(\"/n\", x.size())\n",
    "        x = self.top(x)\n",
    "        return x\n",
    "        \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        #old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "        #self.tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 50265)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=32,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e14bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:35.208591Z",
     "iopub.status.busy": "2022-07-07T12:34:35.208168Z",
     "iopub.status.idle": "2022-07-07T12:34:35.427762Z",
     "shell.execute_reply": "2022-07-07T12:34:35.427050Z"
    },
    "papermill": {
     "duration": 0.244676,
     "end_time": "2022-07-07T12:34:35.430276",
     "exception": false,
     "start_time": "2022-07-07T12:34:35.185600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base\"\n",
    "BS = 32\n",
    "NW = 2\n",
    "test_df[\"pct_rank\"] = 0\n",
    "MAX_LEN = 64\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf1b74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:35.476689Z",
     "iopub.status.busy": "2022-07-07T12:34:35.475982Z",
     "iopub.status.idle": "2022-07-07T12:34:35.871432Z",
     "shell.execute_reply": "2022-07-07T12:34:35.870498Z"
    },
    "papermill": {
     "duration": 0.420954,
     "end_time": "2022-07-07T12:34:35.873779",
     "exception": false,
     "start_time": "2022-07-07T12:34:35.452825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0883148c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:35.921079Z",
     "iopub.status.busy": "2022-07-07T12:34:35.920245Z",
     "iopub.status.idle": "2022-07-07T12:34:35.930280Z",
     "shell.execute_reply": "2022-07-07T12:34:35.929395Z"
    },
    "papermill": {
     "duration": 0.0365,
     "end_time": "2022-07-07T12:34:35.933175",
     "exception": false,
     "start_time": "2022-07-07T12:34:35.896675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 10431,  2741,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 25980,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 39154,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,  3698,  1215, 33480],\n",
      "        [    0,   170,    40,  ...,  3698,  1215, 33480],\n",
      "        [    0,   170,    67,  ...,  3698,  1215, 33480]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55efec4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:35.979864Z",
     "iopub.status.busy": "2022-07-07T12:34:35.979190Z",
     "iopub.status.idle": "2022-07-07T12:34:35.992943Z",
     "shell.execute_reply": "2022-07-07T12:34:35.992191Z"
    },
    "papermill": {
     "duration": 0.038538,
     "end_time": "2022-07-07T12:34:35.994678",
     "exception": false,
     "start_time": "2022-07-07T12:34:35.956140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(tbar)):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    #model.load_state_dict(torch.load(ckpt_path))\n",
    "    state_dict = torch.load(ckpt_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    BS = 32\n",
    "    NW = 2\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    print(model)\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03fa445f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:34:36.039743Z",
     "iopub.status.busy": "2022-07-07T12:34:36.039179Z",
     "iopub.status.idle": "2022-07-07T12:35:01.726522Z",
     "shell.execute_reply": "2022-07-07T12:35:01.723693Z"
    },
    "papermill": {
     "duration": 25.711974,
     "end_time": "2022-07-07T12:35:01.728722",
     "exception": false,
     "start_time": "2022-07-07T12:34:36.016748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkdownModel(\n",
      "  (model): LongformerModel(\n",
      "    (embeddings): LongformerEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): LongformerEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): LongformerPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
      ")\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base/\"\n",
    "ckpt_path = \"../input/ai4code-models/model-0 (4).bin\"\n",
    "y_test_1 = predict(model_path, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26bbe41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:35:01.787087Z",
     "iopub.status.busy": "2022-07-07T12:35:01.786290Z",
     "iopub.status.idle": "2022-07-07T12:35:01.792744Z",
     "shell.execute_reply": "2022-07-07T12:35:01.791945Z"
    },
    "papermill": {
     "duration": 0.037027,
     "end_time": "2022-07-07T12:35:01.794569",
     "exception": false,
     "start_time": "2022-07-07T12:35:01.757542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737f91bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:35:01.852561Z",
     "iopub.status.busy": "2022-07-07T12:35:01.851909Z",
     "iopub.status.idle": "2022-07-07T12:35:01.867878Z",
     "shell.execute_reply": "2022-07-07T12:35:01.867190Z"
    },
    "papermill": {
     "duration": 0.047068,
     "end_time": "2022-07-07T12:35:01.869751",
     "exception": false,
     "start_time": "2022-07-07T12:35:01.822683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db e25aa9bd 1372ae9b 90ed07ab f9893819 7f388a41 ba55e576 39e937ec 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 ed415c3c d3f5c397 7f53de45 8ce62db4 bac960d3 89b1fdd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     0a226b6a ddfd239c 8cb8d28a c6cd22db e25aa9bd 1372ae9b 90ed07ab f9893819 7f388a41 ba55e576 39e937ec 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 ed415c3c d3f5c397 7f53de45 8ce62db4 bac960d3 89b1fdd2...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1997368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T12:35:01.928679Z",
     "iopub.status.busy": "2022-07-07T12:35:01.928426Z",
     "iopub.status.idle": "2022-07-07T12:35:01.935935Z",
     "shell.execute_reply": "2022-07-07T12:35:01.935295Z"
    },
    "papermill": {
     "duration": 0.039338,
     "end_time": "2022-07-07T12:35:01.937685",
     "exception": false,
     "start_time": "2022-07-07T12:35:01.898347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd1428",
   "metadata": {
    "papermill": {
     "duration": 0.028115,
     "end_time": "2022-07-07T12:35:01.993788",
     "exception": false,
     "start_time": "2022-07-07T12:35:01.965673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 87.709577,
   "end_time": "2022-07-07T12:35:04.941911",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-07T12:33:37.232334",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
