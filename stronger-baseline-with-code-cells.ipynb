{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e940d4a",
   "metadata": {
    "papermill": {
     "duration": 0.016501,
     "end_time": "2022-06-28T17:49:57.708983",
     "exception": false,
     "start_time": "2022-06-28T17:49:57.692482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49587460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:57.740323Z",
     "iopub.status.busy": "2022-06-28T17:49:57.739959Z",
     "iopub.status.idle": "2022-06-28T17:49:57.813588Z",
     "shell.execute_reply": "2022-06-28T17:49:57.812953Z"
    },
    "papermill": {
     "duration": 0.091767,
     "end_time": "2022-06-28T17:49:57.815434",
     "exception": false,
     "start_time": "2022-06-28T17:49:57.723667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b244a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:57.846613Z",
     "iopub.status.busy": "2022-06-28T17:49:57.846419Z",
     "iopub.status.idle": "2022-06-28T17:49:57.926152Z",
     "shell.execute_reply": "2022-06-28T17:49:57.925146Z"
    },
    "papermill": {
     "duration": 0.097442,
     "end_time": "2022-06-28T17:49:57.927883",
     "exception": false,
     "start_time": "2022-06-28T17:49:57.830441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 95.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3583bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:57.961450Z",
     "iopub.status.busy": "2022-06-28T17:49:57.960866Z",
     "iopub.status.idle": "2022-06-28T17:49:57.980372Z",
     "shell.execute_reply": "2022-06-28T17:49:57.979575Z"
    },
    "papermill": {
     "duration": 0.038748,
     "end_time": "2022-06-28T17:49:57.982869",
     "exception": false,
     "start_time": "2022-06-28T17:49:57.944121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa80fac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:58.018875Z",
     "iopub.status.busy": "2022-06-28T17:49:58.018678Z",
     "iopub.status.idle": "2022-06-28T17:49:58.028549Z",
     "shell.execute_reply": "2022-06-28T17:49:58.027893Z"
    },
    "papermill": {
     "duration": 0.029477,
     "end_time": "2022-06-28T17:49:58.030192",
     "exception": false,
     "start_time": "2022-06-28T17:49:58.000715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2927f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:58.063658Z",
     "iopub.status.busy": "2022-06-28T17:49:58.063134Z",
     "iopub.status.idle": "2022-06-28T17:49:58.078929Z",
     "shell.execute_reply": "2022-06-28T17:49:58.077977Z"
    },
    "papermill": {
     "duration": 0.034344,
     "end_time": "2022-06-28T17:49:58.080697",
     "exception": false,
     "start_time": "2022-06-28T17:49:58.046353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 734.46it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e02393e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:58.116159Z",
     "iopub.status.busy": "2022-06-28T17:49:58.115949Z",
     "iopub.status.idle": "2022-06-28T17:49:58.122487Z",
     "shell.execute_reply": "2022-06-28T17:49:58.121563Z"
    },
    "papermill": {
     "duration": 0.027739,
     "end_time": "2022-06-28T17:49:58.125739",
     "exception": false,
     "start_time": "2022-06-28T17:49:58.098000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0009d135ece78d': {'total_code': 7,\n",
       "  'total_md': 6,\n",
       "  'codes': ['import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import StandardScaler\\nfrom s',\n",
       "   \"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf\",\n",
       "   'numerical_data = df.loc[:, ~df.columns.isin([\\'id\\', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize([\\'B\\',\\'M\\'])[0]\\n\\nheader_labels = pd.DataFrame(data=labels, columns=[\"diagnosis\"])',\n",
       "   'def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    # data_1 = scale(data_1)\\n    # data_2 = scale(data_2)\\n\\n    range =  np.random.randn(le',\n",
       "   '# Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"radius_mean\"], numerical_data[\"radius_worst\"], \"Mean Radius vs Worst Radius\", \"Mean Ra',\n",
       "   '# Scaling Data\\nscaler = StandardScaler()\\nscaler.fit(numerical_data)\\n# print(scaled_data)\\n\\n# Assigning Variables\\nX = scaler.transform(numerical_data)\\ny = labels\\n\\nmy_imputer = SimpleImputer()\\npd.DataFra',\n",
       "   '# 3. Implementing PCA on X (green for benign; red for malignant)\\n################################################################\\n\\n# PCA\\nPCA3=PCA(n_components=2)\\n# print(X.shape)\\nPCA3.fit(X)\\nXPCA = PC']},\n",
       " '0010483c12ba9b': {'total_code': 9,\n",
       "  'total_md': 1,\n",
       "  'codes': [\"%reset -f \\n\\nif 1:\\n    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer\\n    import shutil\\n    from pathlib import Path\\n\\n    transformers_path = Path('/opt/conda/lib/python3.7/site-packages/t\",\n",
       "   \"#config \\n\\ndiscourse_marker_to_label = {\\n    'O': 0,\\n    'B-Lead': 1,\\n    'I-Lead': 2,\\n    'B-Position': 3,\\n    'I-Position': 4,\\n    'B-Claim': 5,\\n    'I-Claim': 6,\\n    'B-Counterclaim': 7,\\n    'I-Coun\",\n",
       "   \"#data\\n\\ndf_text=[]\\nfor id in valid_id:\\n    text_file = text_dir +'/%s.txt'%id\\n    with open(text_file, 'r') as f:\\n        text = f.read()\\n\\n    text = text.replace(u'\\\\xa0', u' ')\\n    text = text.rstrip(\",\n",
       "   '#net\\n\\nfrom bigbird_base_model import Net as BidBirdBaseNet\\nfrom longformer_base_model import Net as LongformerBaseNet\\nfrom bigbird_large_model import Net as BidBirdLargeNet\\nfrom longformer_large_model',\n",
       "   '#processing\\n\\ndef text_to_word(text):\\n    word = text.split()\\n    word_offset = []\\n\\n    start = 0\\n    for w in word:\\n        r = text[start:].find(w)\\n\\n        if r==-1:\\n            raise NotImplemented',\n",
       "   '## main submission function !!!!\\n\\n\\ndef run_submit():\\n    if is_debug: print(\"THIS IS DEBUG ####################################\")\\n    all_time = 0\\n    print(\\'start\\', memory_used_to_str())\\n\\n    ensembl',\n",
       "   '#check function\\ndef run_check_dataset():\\n\\n    tokenizer = net[0].get_tokenizer()\\n    dataset = FeedbackDataset(df_text, tokenizer, max_length)\\n\\n    for i in range(5):\\n        r = dataset[i]\\n        pr',\n",
       "   \"# '''\\n# cross validation results \\n# WITHOUT SORTED TEXT INPUT #############################################\\n# ../input/feedback-prize-submit-01/microsoft-deberta-large ( one model )\\n# 202/202   1 min \",\n",
       "   '#run_check_dataset()\\nrun_submit()']},\n",
       " '0010a919d60e4f': {'total_code': 27,\n",
       "  'total_md': 35,\n",
       "  'codes': ['\\n# Essential\\nimport numpy as np\\nimport pandas as pd\\n\\n# Data Visualization\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.ticker import PercentFormatter\\n\\n\\n# Models\\nimport xgboost as xgb\\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.ensemble import StackingClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\n\\n\\n# Model evaluation and tuning\\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\\nfrom sklearn.metrics import classification_report\\nimport shap\\n\\n\\n# Imputing and scaling \\nfrom sklearn.impute._knn import KNNImputer\\nfrom sklearn.preprocessing import StandardScaler\\n\\n\\n\\n\\n\\n',\n",
       "   \"train_data = pd.read_csv('../input/titanic/train.csv')\\n# train_data['Survived'] = train_data['Survived'].astype(int)\\ntest_data = pd.read_csv('../input/titanic/test.csv')\\nfull_data =  train_data.append(test_data)\\n\\ntrain_data.head()\",\n",
       "   \"print('Number of rows ',len(train_data))\\nprint(train_data.isnull().sum())\",\n",
       "   \"full_data['FamilyMembers'] = full_data['SibSp'] + full_data['Parch']\\ntrain_data['FamilyMembers'] = train_data['SibSp'] + train_data['Parch']\",\n",
       "   \"\\nfig,ax = plt.subplots(1,2,figsize=(10,6))\\nsns.countplot(x='FamilyMembers',hue='Survived',data=train_data,ax=ax[0]).set(title='How many passengers survived? \\nGrouped by number of family members on board',ylabel='Survived',xlabel='Family members')\\nsns.barplot(x='Sex',y='Survived',hue='Pclass',data=train_data,ax=ax[1]).set(title='How many passengers survived? (in percents)',ylabel='Percentage')\\nax[1].yaxis.set_major_formatter(PercentFormatter(xmax=1.00))\\n\",\n",
       "   \"#Passenger considered solo if he has no family members on board\\nfull_data['IsSolo'] = (full_data['FamilyMembers'] == 0).astype(int)\\n\\n# test_data['FamilyMembers'] = test_data['SibSp']+test_data['Parch']\\n\\n\\n# Replace string value to numbers. There's 2 nan values in test data, we will change them to value of most common port ('S') \\nfull_data['Embarked'] = full_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2,np.nan:0} ).astype(int)\\n\\n# Replace string value of sex to numbers 1 - female, 0 - male\\nfull_data['Sex'] = (full_data['Sex'] == 'female').astype(int)\\n\\n\\n\\n#There's 1 missing value for Fare in test dataset, let's fill it with mean value\\nfull_data['Fare'].fillna(full_data['Fare'].mean(), inplace=True)\\n\",\n",
       "   '# Extracting last name from Name feature\\nfull_data[\\'Last_Name\\'] = full_data[\\'Name\\'].apply(lambda x: str.split(x, \",\")[0])\\n\\n# Filling default value of family/group survival as mean of individual survival \\nfull_data[\\'Family_Survival\\'] = train_data[\\'Survived\\'].mean()\\n\\n\\n# for loop to find family members (family with same surname)\\nfor grp, grp_df in full_data[[\\'Survived\\',\\'Name\\', \\'Last_Name\\', \\'Fare\\', \\'Ticket\\', \\'PassengerId\\',\\n                           \\'SibSp\\', \\'Parch\\', \\'Age\\', \\'Cabin\\']].groupby([\\'Last_Name\\', \\'Fare\\']):\\n    if (len(grp_df) != 1):\\n        for ind, row in grp_df.iterrows():\\n            #check if whole family doesn\\'t have \\'Survived\\' value  \\n            if (np.isnan(grp_df[\\'Survived\\']).all()):\\n                continue\\n            average_family_score = (grp_df.drop(ind)[\\'Survived\\'].mean())\\n            #check if average_family_score is nan, it happens when only current passenger has \\'Survived\\' value\\n            if np.isnan(average_family_score):\\n                average_family_score = row[\\'Survived\\']\\n            average_family_score = round(average_family_score)   \\n            passID = row[\\'PassengerId\\']\\n            full_data.loc[full_data[\\'PassengerId\\'] == passID, \\'Family_Survival\\'] = average_family_score\\n\\n# for loop to find group of passengers who bought ticket together (friends,relatives)\\nfor _, grp_df in full_data.groupby(\\'Ticket\\'):\\n    if (len(grp_df) != 1):\\n        for ind, row in grp_df.iterrows():\\n            if (row[\\'Family_Survival\\'] == 0) | (row[\\'Family_Survival\\'] == 0.5):\\n                if (np.isnan(grp_df[\\'Survived\\']).all()):\\n                    continue\\n                average_family_score = (grp_df.drop(ind)[\\'Survived\\'].mean())\\n                if np.isnan(average_family_score):\\n                    average_family_score = row[\\'Survived\\']\\n                average_family_score = round(average_family_score)   \\n                passID = row[\\'PassengerId\\']\\n                full_data.loc[full_data[\\'PassengerId\\'] == passID, \\'Family_Survival\\'] = average_family_score',\n",
       "   'full_data.head()',\n",
       "   \"features = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']\\ny = train_data['Survived'].ravel()\\nX_train,X_val,y_train,y_val = train_test_split(train_data[features],y,test_size=0.20,random_state=111)\",\n",
       "   'def test_models(model,X,y_train):\\n    key = type(model).__name__\\n    model.fit(X,y_train)\\n    model_score =model.score(X,y_train)\\n    model_score=cross_val_score(model,X,y_train,cv=5).mean()\\n    if key not in summary:\\n        summary[key] = []\\n    summary[key].append(model_score)\\n    return summary',\n",
       "   \"scaler = StandardScaler()\\n\\nfeatures = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']\\nsummary={}\\nmodels_to_check= [SVC(),KNeighborsClassifier(),xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss'),LogisticRegression(solver='liblinear'),GaussianNB(),RandomForestClassifier()]\\n\\nfor item in models_to_check:\\n    summary = test_models(item,X_train[features],y_train)\\n\\nprint(X_train[features].columns)\\nX = scaler.fit_transform(X_train[features])\\n\\n\\nfor item in models_to_check:\\n    summary = test_models(item,X,y_train)\\n\\nsummary = pd.DataFrame.from_dict(summary,orient='index',columns=['Without scaler','With scaler'])\\nprint(summary)\\n;\\n\",\n",
       "   'model = model.fit(X_val,y_val)\\nexplainer = shap.Explainer(model)\\nshap_values = explainer(X_val)\\n\\nshap.summary_plot(shap_values)',\n",
       "   'def GridSearchCVWrapper(model,parameters, X_train,X_val,y_train,y_val):\\n\\n    clf = GridSearchCV(estimator=model, param_grid=parameters,n_jobs=-1,\\n                    cv=StratifiedKFold(n_splits=5), \\n                    scoring=[\\'accuracy\\',\\'recall\\',\\'f1\\',\\'roc_auc\\'],\\n                    verbose=1,refit=\\'roc_auc\\')\\n    clf.fit(X_train,y_train)          \\n    preds = clf.best_estimator_.predict(X_val)\\n    print(classification_report(preds,y_val))\\n    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring = \"roc_auc\")\\n    print(\"Scores:\", scores)\\n    print(f\"Mean:{scores.mean()} ± {scores.std()}\")\\n\\n    return clf ',\n",
       "   'Logistic_model_params= {\\'penalty\\' : [\\'l1\\', \\'l2\\'],\\n                        \\'C\\' : np.logspace(-4, 4, 20),\\n                        \\'solver\\' : [\\'liblinear\\']}\\n\\nLogistic_model = GridSearchCVWrapper(LogisticRegression(),Logistic_model_params,X_train,X_val,y_train,y_val)\\nprint(f\"\\nBest params for Logistic Regression are:\")\\nprint(Logistic_model.best_estimator_)',\n",
       "   'SVM_model_params = {\\'C\\':np.logspace(-2,1,4),\\n                    \\'gamma\\':np.logspace(-2,1,4),}\\n                    \\nSVM_model = GridSearchCVWrapper(SVC(),SVM_model_params, X_train,X_val,y_train,y_val)\\nprint(f\"\\nBest params for SVM are:\")\\nprint(SVM_model.best_estimator_)',\n",
       "   '\\nRF_model_params = { \\'n_estimators\\': [200,350,500],\\n               \\'max_features\\': [\\'auto\\'],\\n               \\'max_depth\\': [2,5,None],\\n               \\'min_samples_split\\': [5, 10],\\n               \\'min_samples_leaf\\': [2, 4],\\n               \\'bootstrap\\': [True],\\n               \\'random_state\\':[1]}\\nRF_model = GridSearchCVWrapper(RandomForestClassifier(),RF_model_params,X_train,X_val,y_train,y_val)\\n\\nprint(f\"\\nBest params for Random Forest are:\")\\nprint(RF_model.best_estimator_)',\n",
       "   '#! for some reason this cell runs horribly slow in kaggle, so I truncated most of the parameters. I used params which i got from run on my pc.\\nXgb_model_parameters = {\\n            \\'n_estimators\\': [200],\\n            \\'colsample_bytree\\': [0.7],\\n            \\'max_depth\\': [15],\\n            \\'reg_alpha\\': [1.1],\\n            \\'reg_lambda\\': [1.2],\\n            \\'n_jobs\\':[-1]}\\n\\nXgb_model = GridSearchCVWrapper(xgb.XGBClassifier(use_label_encoder=False,eval_metric=\\'logloss\\'),Xgb_model_parameters,X_train,X_val,y_train,y_val)\\nprint(f\"\\nBest params for XGBoost are:\")\\nprint(Xgb_model.best_estimator_)\\n',\n",
       "   'KNN_model_params= {\\'n_neighbors\\':np.arange(1,30,2),\\n                    \\'leaf_size\\':np.arange(1,15,2),\\n                    \\'p\\':[1,2]}\\nKNN_model = GridSearchCVWrapper(KNeighborsClassifier(),KNN_model_params,X_train,X_val,y_train,y_val)\\n\\nprint(f\"\\nBest params for K Neighbors are:\")\\nprint(KNN_model.best_estimator_)',\n",
       "   'data_of_classifier = pd.DataFrame()\\nclassifiers = [SVM_model.best_estimator_,Xgb_model.best_estimator_, Logistic_model.best_estimator_, Gaussian_model.best_estimator_,RF_model.best_estimator_,KNN_model.best_estimator_]\\nfor i in classifiers:\\n    fit_classifier = i.fit(X_train,y_train)\\n    data_of_classifier[type(i).__name__] = i.predict(X_val)\\n    print(\\'Score of\\',type(i).__name__,\\':\\')\\n    print(cross_val_score(fit_classifier, X_train, y_train, cv=5, scoring = \"roc_auc\").mean())\\nsns.heatmap(data_of_classifier.astype(float).corr(),annot=True)',\n",
       "   \"\\nestimators = [#('SVM',SVM_model.best_estimator_),\\n              ('XGB',Xgb_model.best_estimator_),\\n              ('Logistic',Logistic_model.best_estimator_)\\n               # ('Random Forest',Gaussian_model.best_estimator_),\\n               #('KNN',KNN_model.best_estimator_)\\n]\\n\\nstacking_clf = StackingClassifier(estimators = estimators,final_estimator=RF_model.best_estimator_)\\n\\nstacking_clf.fit(X,y)\\n\\npredictions =  stacking_clf.predict(data_to_test)\\npredictions =predictions.astype(int)\\nfinal_results = pd.DataFrame({ 'PassengerId':test_data.PassengerId ,'Survived':predictions })\\nfinal_results.to_csv('../working/submission.csv',index=False)\"]},\n",
       " '0028856e09c5b7': {'total_code': 3,\n",
       "  'total_md': 1,\n",
       "  'codes': ['sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size',\n",
       "   ' types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html\\n#  axis=1)\\n     copy\\n#remember  Functi',\n",
       "   \"#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '.1f',ax=ax)\\nplt.show()\\n\\ndata1.hist(figsize=(16, ylabelsize=8); having plt.subplots(figs\"]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b01c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:49:58.163995Z",
     "iopub.status.busy": "2022-06-28T17:49:58.163805Z",
     "iopub.status.idle": "2022-06-28T17:50:04.328104Z",
     "shell.execute_reply": "2022-06-28T17:50:04.327375Z"
    },
    "papermill": {
     "duration": 6.18699,
     "end_time": "2022-06-28T17:50:04.330330",
     "exception": false,
     "start_time": "2022-06-28T17:49:58.143340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "        \n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "        return x\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=23,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c667a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:04.368177Z",
     "iopub.status.busy": "2022-06-28T17:50:04.367712Z",
     "iopub.status.idle": "2022-06-28T17:50:04.613232Z",
     "shell.execute_reply": "2022-06-28T17:50:04.612494Z"
    },
    "papermill": {
     "duration": 0.266824,
     "end_time": "2022-06-28T17:50:04.615312",
     "exception": false,
     "start_time": "2022-06-28T17:50:04.348488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base\"\n",
    "BS = 32\n",
    "NW = 2\n",
    "test_df[\"pct_rank\"] = 0\n",
    "MAX_LEN = 64\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497ee15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:04.653353Z",
     "iopub.status.busy": "2022-06-28T17:50:04.652838Z",
     "iopub.status.idle": "2022-06-28T17:50:05.003884Z",
     "shell.execute_reply": "2022-06-28T17:50:05.002960Z"
    },
    "papermill": {
     "duration": 0.372615,
     "end_time": "2022-06-28T17:50:05.006287",
     "exception": false,
     "start_time": "2022-06-28T17:50:04.633672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7d878b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:05.045461Z",
     "iopub.status.busy": "2022-06-28T17:50:05.045220Z",
     "iopub.status.idle": "2022-06-28T17:50:05.054221Z",
     "shell.execute_reply": "2022-06-28T17:50:05.052354Z"
    },
    "papermill": {
     "duration": 0.030413,
     "end_time": "2022-06-28T17:50:05.055932",
     "exception": false,
     "start_time": "2022-06-28T17:50:05.025519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 10431,  2741,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 25980,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 39154,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,     1,     1,     1],\n",
      "        [    0,   170,    40,  ...,     1,     1,     1],\n",
      "        [    0,   170,    67,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157e5ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:05.094348Z",
     "iopub.status.busy": "2022-06-28T17:50:05.093936Z",
     "iopub.status.idle": "2022-06-28T17:50:05.105667Z",
     "shell.execute_reply": "2022-06-28T17:50:05.105002Z"
    },
    "papermill": {
     "duration": 0.032208,
     "end_time": "2022-06-28T17:50:05.107243",
     "exception": false,
     "start_time": "2022-06-28T17:50:05.075035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(tbar)):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    #model.load_state_dict(torch.load(ckpt_path))\n",
    "    state_dict = torch.load(ckpt_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    BS = 32\n",
    "    NW = 2\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    print(model)\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c13efef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:05.144959Z",
     "iopub.status.busy": "2022-06-28T17:50:05.144279Z",
     "iopub.status.idle": "2022-06-28T17:50:24.008891Z",
     "shell.execute_reply": "2022-06-28T17:50:24.007989Z"
    },
    "papermill": {
     "duration": 18.886375,
     "end_time": "2022-06-28T17:50:24.011438",
     "exception": false,
     "start_time": "2022-06-28T17:50:05.125063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkdownModel(\n",
      "  (model): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
      ")\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:02,  1.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base/\"\n",
    "ckpt_path = \"../input/ai4code-models/model-4.bin\"\n",
    "y_test_1 = predict(model_path, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10101e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:24.092755Z",
     "iopub.status.busy": "2022-06-28T17:50:24.092472Z",
     "iopub.status.idle": "2022-06-28T17:50:24.100185Z",
     "shell.execute_reply": "2022-06-28T17:50:24.099514Z"
    },
    "papermill": {
     "duration": 0.050704,
     "end_time": "2022-06-28T17:50:24.102455",
     "exception": false,
     "start_time": "2022-06-28T17:50:24.051751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8932b44a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:24.181774Z",
     "iopub.status.busy": "2022-06-28T17:50:24.181441Z",
     "iopub.status.idle": "2022-06-28T17:50:24.201028Z",
     "shell.execute_reply": "2022-06-28T17:50:24.200078Z"
    },
    "papermill": {
     "duration": 0.061764,
     "end_time": "2022-06-28T17:50:24.203192",
     "exception": false,
     "start_time": "2022-06-28T17:50:24.141428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c c6cd22db 1372ae9b ba55e576 90ed07ab 0a226b6a 8cb8d28a e25aa9bd f9893819 7f388a41 39e937ec 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 7f270e34 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae ea06b4d0 3f4a105f 7f53de45 4ae17669 d3f5c397 80433cf3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     ddfd239c c6cd22db 1372ae9b ba55e576 90ed07ab 0a226b6a 8cb8d28a e25aa9bd f9893819 7f388a41 39e937ec 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 7f270e34 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae ea06b4d0 3f4a105f 7f53de45 4ae17669 d3f5c397 80433cf3...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31db99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T17:50:24.284347Z",
     "iopub.status.busy": "2022-06-28T17:50:24.284121Z",
     "iopub.status.idle": "2022-06-28T17:50:24.291708Z",
     "shell.execute_reply": "2022-06-28T17:50:24.291077Z"
    },
    "papermill": {
     "duration": 0.050029,
     "end_time": "2022-06-28T17:50:24.293406",
     "exception": false,
     "start_time": "2022-06-28T17:50:24.243377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf11f6f",
   "metadata": {
    "papermill": {
     "duration": 0.024222,
     "end_time": "2022-06-28T17:50:24.342170",
     "exception": false,
     "start_time": "2022-06-28T17:50:24.317948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.35889,
   "end_time": "2022-06-28T17:50:27.856448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-28T17:49:49.497558",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
