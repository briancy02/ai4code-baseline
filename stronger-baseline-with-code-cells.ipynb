{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df23d2c5",
   "metadata": {
    "papermill": {
     "duration": 0.028079,
     "end_time": "2022-07-25T18:10:12.913674",
     "exception": false,
     "start_time": "2022-07-25T18:10:12.885595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5459d078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:12.968201Z",
     "iopub.status.busy": "2022-07-25T18:10:12.967802Z",
     "iopub.status.idle": "2022-07-25T18:10:19.928305Z",
     "shell.execute_reply": "2022-07-25T18:10:19.927565Z"
    },
    "papermill": {
     "duration": 6.98979,
     "end_time": "2022-07-25T18:10:19.930467",
     "exception": false,
     "start_time": "2022-07-25T18:10:12.940677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.models.longformer.modeling_longformer import LongformerSelfAttention\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6da20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:19.978451Z",
     "iopub.status.busy": "2022-07-25T18:10:19.978214Z",
     "iopub.status.idle": "2022-07-25T18:10:20.053941Z",
     "shell.execute_reply": "2022-07-25T18:10:20.053247Z"
    },
    "papermill": {
     "duration": 0.102477,
     "end_time": "2022-07-25T18:10:20.056203",
     "exception": false,
     "start_time": "2022-07-25T18:10:19.953726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 97.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605a7de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:20.109771Z",
     "iopub.status.busy": "2022-07-25T18:10:20.109163Z",
     "iopub.status.idle": "2022-07-25T18:10:20.128153Z",
     "shell.execute_reply": "2022-07-25T18:10:20.127512Z"
    },
    "papermill": {
     "duration": 0.048108,
     "end_time": "2022-07-25T18:10:20.129931",
     "exception": false,
     "start_time": "2022-07-25T18:10:20.081823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c04f922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:20.181283Z",
     "iopub.status.busy": "2022-07-25T18:10:20.180695Z",
     "iopub.status.idle": "2022-07-25T18:10:20.190855Z",
     "shell.execute_reply": "2022-07-25T18:10:20.190156Z"
    },
    "papermill": {
     "duration": 0.037164,
     "end_time": "2022-07-25T18:10:20.192428",
     "exception": false,
     "start_time": "2022-07-25T18:10:20.155264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069e9dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:20.243922Z",
     "iopub.status.busy": "2022-07-25T18:10:20.243251Z",
     "iopub.status.idle": "2022-07-25T18:10:20.257356Z",
     "shell.execute_reply": "2022-07-25T18:10:20.256659Z"
    },
    "papermill": {
     "duration": 0.041615,
     "end_time": "2022-07-25T18:10:20.259315",
     "exception": false,
     "start_time": "2022-07-25T18:10:20.217700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 866.05it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aab2fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:10:20.311672Z",
     "iopub.status.busy": "2022-07-25T18:10:20.311325Z",
     "iopub.status.idle": "2022-07-25T18:11:00.315639Z",
     "shell.execute_reply": "2022-07-25T18:11:00.314870Z"
    },
    "papermill": {
     "duration": 40.032759,
     "end_time": "2022-07-25T18:11:00.317738",
     "exception": false,
     "start_time": "2022-07-25T18:10:20.284979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "python_files = sorted(Path('../input/codesearchnet/python/python/final/jsonl/train/').glob('**/*.jsonl'))\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "pydf = jsonl_list_to_dataframe(python_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5c253f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:00.371065Z",
     "iopub.status.busy": "2022-07-25T18:11:00.370516Z",
     "iopub.status.idle": "2022-07-25T18:11:00.398326Z",
     "shell.execute_reply": "2022-07-25T18:11:00.397538Z"
    },
    "papermill": {
     "duration": 0.05745,
     "end_time": "2022-07-25T18:11:00.401334",
     "exception": false,
     "start_time": "2022-07-25T18:11:00.343884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...</td>\n",
       "      <td>Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...</td>\n",
       "      <td>Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visually, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...</td>\n",
       "      <td>[def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....</td>\n",
       "      <td>Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...</td>\n",
       "      <td>[Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>bin/extract_shared_or_unique_otuids.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...</td>\n",
       "      <td>def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...</td>\n",
       "      <td>[def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...</td>\n",
       "      <td>Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...</td>\n",
       "      <td>[Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34</td>\n",
       "      <td>def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...</td>\n",
       "      <td>[def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...</td>\n",
       "      <td>Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73</td>\n",
       "      <td>def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...</td>\n",
       "      <td>[def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...</td>\n",
       "      <td>Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...</td>\n",
       "      <td>[Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108</td>\n",
       "      <td>def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...</td>\n",
       "      <td>[def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...</td>\n",
       "      <td>Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...</td>\n",
       "      <td>[Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412178 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            repo                                    path  \\\n",
       "0      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "1      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "2      ageitgey/face_recognition        examples/face_recognition_knn.py   \n",
       "3      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "4      ageitgey/face_recognition                 face_recognition/api.py   \n",
       "...                          ...                                     ...   \n",
       "29995       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29996       smdabdoub/phylotoast  bin/extract_shared_or_unique_otuids.py   \n",
       "29997       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29998       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "29999       smdabdoub/phylotoast                      phylotoast/util.py   \n",
       "\n",
       "                                                                                                                           url  \\\n",
       "0      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "1      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "2      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition...   \n",
       "3      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "4      https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/face_recognition/api.py#L...   \n",
       "...                                                                                                                        ...   \n",
       "29995  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29996  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/bin/extract_shared_or_unique_o...   \n",
       "29997         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L20-L34   \n",
       "29998         https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L37-L73   \n",
       "29999        https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L76-L108   \n",
       "\n",
       "                                                                                                                          code  \\\n",
       "0      def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \"\"\"\\n    Tra...   \n",
       "1      def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in gi...   \n",
       "2      def show_prediction_labels_on_image(img_path, predictions):\\n    \"\"\"\\n    Shows the face recognition results visuall...   \n",
       "3      def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) or...   \n",
       "4      def _trim_css_to_bounds(css, image_shape):\\n    \"\"\"\\n    Make sure a tuple in (top, right, bottom, left) order is wi...   \n",
       "...                                                                                                                        ...   \n",
       "29995  def shared_otuids(groups):\\n    \"\"\"\\n    Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type g...   \n",
       "29996  def write_uniques(path, prefix, uniques):\\n    \"\"\"\\n    Given a path, the method writes out one file for each group ...   \n",
       "29997  def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file by first reading the entire file in...   \n",
       "29998  def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse the records in a FASTA-format file keeping the file open, and reading ...   \n",
       "29999  def parse_map_file(mapFNH):\\n    \"\"\"\\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed o...   \n",
       "\n",
       "                                                                                                                   code_tokens  \\\n",
       "0      [def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, ver...   \n",
       "1      [def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, ...   \n",
       "2      [def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path,...   \n",
       "3      [def, _rect_to_css, (, rect, ), :, return, rect, ., top, (, ), ,, rect, ., right, (, ), ,, rect, ., bottom, (, ), ,,...   \n",
       "4      [def, _trim_css_to_bounds, (, css, ,, image_shape, ), :, return, max, (, css, [, 0, ], ,, 0, ), ,, min, (, css, [, 1...   \n",
       "...                                                                                                                        ...   \n",
       "29995  [def, shared_otuids, (, groups, ), :, for, g, in, sorted, (, groups, ), :, print, (, \"Number of OTUs in {0}: {1}\", ....   \n",
       "29996  [def, write_uniques, (, path, ,, prefix, ,, uniques, ), :, for, group, in, uniques, :, fp, =, osp, ., join, (, path,...   \n",
       "29997  [def, storeFASTA, (, fastaFNH, ), :, fasta, =, file_handle, (, fastaFNH, ), ., read, (, ), return, [, FASTARecord, (...   \n",
       "29998  [def, parseFASTA, (, fastaFNH, ), :, recs, =, [, ], seq, =, [, ], seqID, =, \"\", descr, =, \"\", for, line, in, file_ha...   \n",
       "29999  [def, parse_map_file, (, mapFNH, ), :, m, =, OrderedDict, (, ), map_header, =, None, with, file_handle, (, mapFNH, )...   \n",
       "\n",
       "                                                                                                                     docstring  \\\n",
       "0      Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub...   \n",
       "1      Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recogni...   \n",
       "2      Shows the face recognition results visually.\\n\\n    :param img_path: path to image to be recognized\\n    :param pred...   \n",
       "3      Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib 'rect' ...   \n",
       "4      Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\\n\\n    :param css:  plain t...   \n",
       "...                                                                                                                        ...   \n",
       "29995  Get shared OTUIDs between all unique combinations of groups.\\n\\n    :type groups: Dict\\n    :param groups: {Category...   \n",
       "29996  Given a path, the method writes out one file for each group name in the\\n    uniques dictionary with the file name i...   \n",
       "29997  Parse the records in a FASTA-format file by first reading the entire file into memory.\\n\\n    :type source: path to ...   \n",
       "29998  Parse the records in a FASTA-format file keeping the file open, and reading through\\n    one line at a time.\\n\\n    ...   \n",
       "29999  Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\\n    (default) or a user-suppli...   \n",
       "\n",
       "                                                                                                              docstring_tokens language partition  \n",
       "0                                                 [Trains, a, k, -, nearest, neighbors, classifier, for, face, recognition, .]   python     train  \n",
       "1                                                    [Recognizes, faces, in, given, image, using, a, trained, KNN, classifier]   python     train  \n",
       "2                                                                        [Shows, the, face, recognition, results, visually, .]   python     train  \n",
       "3                             [Convert, a, dlib, rect, object, to, a, plain, tuple, in, (, top, right, bottom, left, ), order]   python     train  \n",
       "4                [Make, sure, a, tuple, in, (, top, right, bottom, left, ), order, is, within, the, bounds, of, the, image, .]   python     train  \n",
       "...                                                                                                                        ...      ...       ...  \n",
       "29995                                                 [Get, shared, OTUIDs, between, all, unique, combinations, of, groups, .]   python     train  \n",
       "29996  [Given, a, path, the, method, writes, out, one, file, for, each, group, name, in, the, uniques, dictionary, with, th...   python     train  \n",
       "29997             [Parse, the, records, in, a, FASTA, -, format, file, by, first, reading, the, entire, file, into, memory, .]   python     train  \n",
       "29998  [Parse, the, records, in, a, FASTA, -, format, file, keeping, the, file, open, and, reading, through, one, line, at,...   python     train  \n",
       "29999  [Opens, a, QIIME, mapping, file, and, stores, the, contents, in, a, dictionary, keyed, on, SampleID, (, default, ), ...   python     train  \n",
       "\n",
       "[412178 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1ed97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:00.455662Z",
     "iopub.status.busy": "2022-07-25T18:11:00.455331Z",
     "iopub.status.idle": "2022-07-25T18:11:01.109596Z",
     "shell.execute_reply": "2022-07-25T18:11:01.108720Z"
    },
    "papermill": {
     "duration": 0.685397,
     "end_time": "2022-07-25T18:11:01.113355",
     "exception": false,
     "start_time": "2022-07-25T18:11:00.427958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 413/413 [00:00<00:00, 8423.40it/s]\n",
      "100%|██████████| 413/413 [00:00<00:00, 11648.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "def get_training_corpus():\n",
    "    to_return = [pydf[i : i + 1000][\"code\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))]\n",
    "    to_return.extend([pydf[i : i + 1000][\"docstring\"]\n",
    "        for i in tqdm(range(0, len(pydf), 1000))])    \n",
    "    return to_return\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "\n",
    "training_corpus = get_training_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde17e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:01.172309Z",
     "iopub.status.busy": "2022-07-25T18:11:01.171785Z",
     "iopub.status.idle": "2022-07-25T18:11:01.175263Z",
     "shell.execute_reply": "2022-07-25T18:11:01.174474Z"
    },
    "papermill": {
     "duration": 0.034612,
     "end_time": "2022-07-25T18:11:01.177141",
     "exception": false,
     "start_time": "2022-07-25T18:11:01.142529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#self.model.embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32cff4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:01.234537Z",
     "iopub.status.busy": "2022-07-25T18:11:01.234308Z",
     "iopub.status.idle": "2022-07-25T18:11:01.252690Z",
     "shell.execute_reply": "2022-07-25T18:11:01.251863Z"
    },
    "papermill": {
     "duration": 0.049631,
     "end_time": "2022-07-25T18:11:01.254671",
     "exception": false,
     "start_time": "2022-07-25T18:11:01.205040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "#         super(MarkdownModel, self).__init__()\n",
    "#         self.model = AutoModel.from_pretrained(model_path)\n",
    "#         self.top = nn.Linear(769, 1)\n",
    "        \n",
    "#     def forward(self, ids, mask, fts):\n",
    "#         x = self.model(ids, mask)[0]\n",
    "#         x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "#         return x\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        #self.max_input_len = 16384\n",
    "        #self.max_input_len += 2\n",
    "        self.attention_window = 512\n",
    "        self.md_max_len = 64\n",
    "        # lengthen model\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "\n",
    "        self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        #global_attention_mask = torch.zeros_like(ids)\n",
    "        #global_attention_mask[:self.md_max_len] = 0\n",
    "        #x = self.model(input_ids=ids, attention_mask=mask)[0]\n",
    "        x = self.model(input_ids=ids, attention_mask=mask)[0]\n",
    "        #print(\"fts\", fts)\n",
    "        x = torch.cat((x[:, 0, :], fts), 1)\n",
    "        #print(\"/n\", x.size())\n",
    "        x = self.top(x)\n",
    "        return x\n",
    "        \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        #old_tokenizer = AutoTokenizer.from_pretrained(\"../input/codebert-base/codebert-base\")\n",
    "        #self.tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 50265)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=23,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdfd9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:01.313245Z",
     "iopub.status.busy": "2022-07-25T18:11:01.313018Z",
     "iopub.status.idle": "2022-07-25T18:11:01.526674Z",
     "shell.execute_reply": "2022-07-25T18:11:01.525917Z"
    },
    "papermill": {
     "duration": 0.245794,
     "end_time": "2022-07-25T18:11:01.529115",
     "exception": false,
     "start_time": "2022-07-25T18:11:01.283321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base\"\n",
    "BS = 32\n",
    "NW = 4\n",
    "test_df[\"pct_rank\"] = 0\n",
    "MAX_LEN = 64\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f16b0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:01.600327Z",
     "iopub.status.busy": "2022-07-25T18:11:01.599738Z",
     "iopub.status.idle": "2022-07-25T18:11:02.282820Z",
     "shell.execute_reply": "2022-07-25T18:11:02.281923Z"
    },
    "papermill": {
     "duration": 0.727703,
     "end_time": "2022-07-25T18:11:02.286547",
     "exception": false,
     "start_time": "2022-07-25T18:11:01.558844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2106d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:02.346372Z",
     "iopub.status.busy": "2022-07-25T18:11:02.345736Z",
     "iopub.status.idle": "2022-07-25T18:11:02.354551Z",
     "shell.execute_reply": "2022-07-25T18:11:02.353743Z"
    },
    "papermill": {
     "duration": 0.042013,
     "end_time": "2022-07-25T18:11:02.358185",
     "exception": false,
     "start_time": "2022-07-25T18:11:02.316172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 10431,  2741,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 25980,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 39154,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,     1,     1,     1],\n",
      "        [    0,   170,    40,  ...,     1,     1,     1],\n",
      "        [    0,   170,    67,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f25d6dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:02.418763Z",
     "iopub.status.busy": "2022-07-25T18:11:02.418546Z",
     "iopub.status.idle": "2022-07-25T18:11:02.431335Z",
     "shell.execute_reply": "2022-07-25T18:11:02.430531Z"
    },
    "papermill": {
     "duration": 0.044786,
     "end_time": "2022-07-25T18:11:02.433228",
     "exception": false,
     "start_time": "2022-07-25T18:11:02.388442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(tbar)):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    #model.load_state_dict(torch.load(ckpt_path))\n",
    "    state_dict = torch.load(ckpt_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    BS = 32\n",
    "    NW = 4\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    print(model)\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfdb4937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:02.493039Z",
     "iopub.status.busy": "2022-07-25T18:11:02.492752Z",
     "iopub.status.idle": "2022-07-25T18:11:16.948114Z",
     "shell.execute_reply": "2022-07-25T18:11:16.947438Z"
    },
    "papermill": {
     "duration": 14.487654,
     "end_time": "2022-07-25T18:11:16.949933",
     "exception": false,
     "start_time": "2022-07-25T18:11:02.462279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.pooler.dense.weight', 'model.pooler.dense.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MarkdownModel(\"../input/codebert-base/codebert-base/\")\n",
    "\n",
    "ckpt_path = \"../input/ai4code-models/model-0 (1).bin\"\n",
    "state_dict = torch.load(ckpt_path)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "    # load params\n",
    "    \n",
    "model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5447640c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:17.009924Z",
     "iopub.status.busy": "2022-07-25T18:11:17.009676Z",
     "iopub.status.idle": "2022-07-25T18:11:17.013245Z",
     "shell.execute_reply": "2022-07-25T18:11:17.012555Z"
    },
    "papermill": {
     "duration": 0.035618,
     "end_time": "2022-07-25T18:11:17.015074",
     "exception": false,
     "start_time": "2022-07-25T18:11:16.979456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.model.embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3527311b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:17.076425Z",
     "iopub.status.busy": "2022-07-25T18:11:17.075854Z",
     "iopub.status.idle": "2022-07-25T18:11:17.079387Z",
     "shell.execute_reply": "2022-07-25T18:11:17.078617Z"
    },
    "papermill": {
     "duration": 0.036159,
     "end_time": "2022-07-25T18:11:17.081546",
     "exception": false,
     "start_time": "2022-07-25T18:11:17.045387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#roberta = AutoModel.from_pretrained(\"../input/roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91876363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:17.142051Z",
     "iopub.status.busy": "2022-07-25T18:11:17.141808Z",
     "iopub.status.idle": "2022-07-25T18:11:17.146386Z",
     "shell.execute_reply": "2022-07-25T18:11:17.145753Z"
    },
    "papermill": {
     "duration": 0.036946,
     "end_time": "2022-07-25T18:11:17.148144",
     "exception": false,
     "start_time": "2022-07-25T18:11:17.111198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe6d8ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:17.208333Z",
     "iopub.status.busy": "2022-07-25T18:11:17.208085Z",
     "iopub.status.idle": "2022-07-25T18:11:17.211237Z",
     "shell.execute_reply": "2022-07-25T18:11:17.210558Z"
    },
    "papermill": {
     "duration": 0.035687,
     "end_time": "2022-07-25T18:11:17.212914",
     "exception": false,
     "start_time": "2022-07-25T18:11:17.177227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#roberta.embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c134fff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:17.272115Z",
     "iopub.status.busy": "2022-07-25T18:11:17.271889Z",
     "iopub.status.idle": "2022-07-25T18:11:18.668643Z",
     "shell.execute_reply": "2022-07-25T18:11:18.667867Z"
    },
    "papermill": {
     "duration": 1.429116,
     "end_time": "2022-07-25T18:11:18.671073",
     "exception": false,
     "start_time": "2022-07-25T18:11:17.241957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_bert = AutoModel.from_pretrained(\"../input/codebert-base/codebert-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29a8ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:18.730911Z",
     "iopub.status.busy": "2022-07-25T18:11:18.730681Z",
     "iopub.status.idle": "2022-07-25T18:11:18.733867Z",
     "shell.execute_reply": "2022-07-25T18:11:18.733197Z"
    },
    "papermill": {
     "duration": 0.035172,
     "end_time": "2022-07-25T18:11:18.735528",
     "exception": false,
     "start_time": "2022-07-25T18:11:18.700356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code_bert.embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c33ca152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:18.795418Z",
     "iopub.status.busy": "2022-07-25T18:11:18.795187Z",
     "iopub.status.idle": "2022-07-25T18:11:18.798501Z",
     "shell.execute_reply": "2022-07-25T18:11:18.797775Z"
    },
    "papermill": {
     "duration": 0.03542,
     "end_time": "2022-07-25T18:11:18.800241",
     "exception": false,
     "start_time": "2022-07-25T18:11:18.764821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#longformer_model = LongformerModel.from_pretrained(\"../input/allenailongformerbase4096/longformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db98e6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:18.860078Z",
     "iopub.status.busy": "2022-07-25T18:11:18.859874Z",
     "iopub.status.idle": "2022-07-25T18:11:23.899505Z",
     "shell.execute_reply": "2022-07-25T18:11:23.898693Z"
    },
    "papermill": {
     "duration": 5.073193,
     "end_time": "2022-07-25T18:11:23.903058",
     "exception": false,
     "start_time": "2022-07-25T18:11:18.829865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkdownModel(\n",
      "  (model): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
      ")\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:02,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base/\"\n",
    "ckpt_path = \"../input/ai4code-models/model-0 (1).bin\"\n",
    "y_test_1 = predict(model_path, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a729a075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:23.976668Z",
     "iopub.status.busy": "2022-07-25T18:11:23.976044Z",
     "iopub.status.idle": "2022-07-25T18:11:23.981932Z",
     "shell.execute_reply": "2022-07-25T18:11:23.981139Z"
    },
    "papermill": {
     "duration": 0.044756,
     "end_time": "2022-07-25T18:11:23.983958",
     "exception": false,
     "start_time": "2022-07-25T18:11:23.939202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c03b2bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:24.055978Z",
     "iopub.status.busy": "2022-07-25T18:11:24.055734Z",
     "iopub.status.idle": "2022-07-25T18:11:24.069656Z",
     "shell.execute_reply": "2022-07-25T18:11:24.068847Z"
    },
    "papermill": {
     "duration": 0.051686,
     "end_time": "2022-07-25T18:11:24.071475",
     "exception": false,
     "start_time": "2022-07-25T18:11:24.019789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db e25aa9bd 1372ae9b ba55e576 90ed07ab f9893819 7f388a41 39e937ec 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 8ce62db4 d3f5c397 5115ebe5 ed415c3c 5e8c5e7e 7f53de45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc 012c9d02 d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     0a226b6a ddfd239c 8cb8d28a c6cd22db e25aa9bd 1372ae9b ba55e576 90ed07ab f9893819 7f388a41 39e937ec 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 8ce62db4 d3f5c397 5115ebe5 ed415c3c 5e8c5e7e 7f53de45...\n",
       "3  0028856e09c5b7                                                                                      eb293dfc 012c9d02 d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52480a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T18:11:24.144773Z",
     "iopub.status.busy": "2022-07-25T18:11:24.144406Z",
     "iopub.status.idle": "2022-07-25T18:11:24.152701Z",
     "shell.execute_reply": "2022-07-25T18:11:24.152066Z"
    },
    "papermill": {
     "duration": 0.046248,
     "end_time": "2022-07-25T18:11:24.154320",
     "exception": false,
     "start_time": "2022-07-25T18:11:24.108072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4890dc5",
   "metadata": {
    "papermill": {
     "duration": 0.035062,
     "end_time": "2022-07-25T18:11:24.224189",
     "exception": false,
     "start_time": "2022-07-25T18:11:24.189127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.460406,
   "end_time": "2022-07-25T18:11:27.077578",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-25T18:10:04.617172",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
