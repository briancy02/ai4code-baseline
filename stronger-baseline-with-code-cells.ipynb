{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05be635a",
   "metadata": {
    "papermill": {
     "duration": 0.018254,
     "end_time": "2022-07-05T14:44:59.866887",
     "exception": false,
     "start_time": "2022-07-05T14:44:59.848633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c68c325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:44:59.901014Z",
     "iopub.status.busy": "2022-07-05T14:44:59.900370Z",
     "iopub.status.idle": "2022-07-05T14:45:08.255843Z",
     "shell.execute_reply": "2022-07-05T14:45:08.255138Z"
    },
    "papermill": {
     "duration": 8.375411,
     "end_time": "2022-07-05T14:45:08.258382",
     "exception": false,
     "start_time": "2022-07-05T14:44:59.882971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.models.longformer.modeling_longformer import LongformerSelfAttention\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fac65a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.291066Z",
     "iopub.status.busy": "2022-07-05T14:45:08.290817Z",
     "iopub.status.idle": "2022-07-05T14:45:08.377622Z",
     "shell.execute_reply": "2022-07-05T14:45:08.375938Z"
    },
    "papermill": {
     "duration": 0.105069,
     "end_time": "2022-07-05T14:45:08.379382",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.274313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 89.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94395fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.413349Z",
     "iopub.status.busy": "2022-07-05T14:45:08.413092Z",
     "iopub.status.idle": "2022-07-05T14:45:08.433265Z",
     "shell.execute_reply": "2022-07-05T14:45:08.432222Z"
    },
    "papermill": {
     "duration": 0.039997,
     "end_time": "2022-07-05T14:45:08.436260",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.396263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85173d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.472351Z",
     "iopub.status.busy": "2022-07-05T14:45:08.471837Z",
     "iopub.status.idle": "2022-07-05T14:45:08.481796Z",
     "shell.execute_reply": "2022-07-05T14:45:08.481067Z"
    },
    "papermill": {
     "duration": 0.02925,
     "end_time": "2022-07-05T14:45:08.483437",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.454187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9398db23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.518965Z",
     "iopub.status.busy": "2022-07-05T14:45:08.518333Z",
     "iopub.status.idle": "2022-07-05T14:45:08.533705Z",
     "shell.execute_reply": "2022-07-05T14:45:08.533002Z"
    },
    "papermill": {
     "duration": 0.035746,
     "end_time": "2022-07-05T14:45:08.536258",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.500512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 757.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0959ec9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.575726Z",
     "iopub.status.busy": "2022-07-05T14:45:08.574546Z",
     "iopub.status.idle": "2022-07-05T14:45:08.578678Z",
     "shell.execute_reply": "2022-07-05T14:45:08.577989Z"
    },
    "papermill": {
     "duration": 0.024659,
     "end_time": "2022-07-05T14:45:08.580358",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.555699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from datasets import load_dataset\n",
    "# raw_datasets = load_dataset(\"code_search_net\", \"python\")\n",
    "# def get_training_corpus():\n",
    "#     return (\n",
    "#         raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "#         for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "#     )\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# old_tokenizer = AutoTokenizer.from_pretrained(\"\")\n",
    "\n",
    "# training_corpus = get_training_corpus()\n",
    "#old_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        #self.tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 50265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a762b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.619019Z",
     "iopub.status.busy": "2022-07-05T14:45:08.618764Z",
     "iopub.status.idle": "2022-07-05T14:45:08.643375Z",
     "shell.execute_reply": "2022-07-05T14:45:08.642695Z"
    },
    "papermill": {
     "duration": 0.047164,
     "end_time": "2022-07-05T14:45:08.645388",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.598224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "#         super(MarkdownModel, self).__init__()\n",
    "#         self.model = AutoModel.from_pretrained(model_path)\n",
    "#         self.top = nn.Linear(769, 1)\n",
    "        \n",
    "#     def forward(self, ids, mask, fts):\n",
    "#         x = self.model(ids, mask)[0]\n",
    "#         x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "#         return x\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        #self.max_input_len = 16384\n",
    "        #self.max_input_len += 2\n",
    "        self.attention_window = 256\n",
    "        self.md_max_len = 64\n",
    "        # lengthen model\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        longformer_model = LongformerModel.from_pretrained(\"../input/allenailongformerbase4096/longformer\")\n",
    "        current_max_input_len, embed_size = self.model.embeddings.position_embeddings.weight.shape\n",
    "#         print(current_max_input_len, embed_size)\n",
    "#         new_encoder_pos_embed = self.model.embeddings.position_embeddings.weight.new_empty(self.max_input_len, embed_size)\n",
    "#         k = 2\n",
    "#         step = current_max_input_len - 2\n",
    "#         while k < self.max_input_len - 1:\n",
    "#             new_encoder_pos_embed[k:(k+step)] = self.model.embeddings.position_embeddings.weight[2:]\n",
    "#             k += step\n",
    "#         self.model.embeddings.position_embeddings.weight.data = new_encoder_pos_embed\n",
    "#         print(self.model.embeddings.position_embeddings.weight.shape)\n",
    "        \n",
    "        \n",
    "        #Attention set up\n",
    "        self.model.config.attention_window = [self.attention_window] * self.model.config.num_hidden_layers\n",
    "        #print(self.model.config.attention_window)\n",
    "        self.model.config.attention_probs_dropout_prob = 0\n",
    "        \n",
    "        for i, layer in enumerate(self.model.encoder.layer):\n",
    "            longformer_self_attn_for_codebert = LongformerSelfAttention(self.model.config, layer_id=i)\n",
    "            longformer_self_attn_for_codebert.query = layer.attention.self.query\n",
    "            longformer_self_attn_for_codebert.key = layer.attention.self.key\n",
    "            longformer_self_attn_for_codebert.value = layer.attention.self.value\n",
    "            \n",
    "            longformer_self_attn_for_codebert.query_global = copy.deepcopy(layer.attention.self.query)\n",
    "            longformer_self_attn_for_codebert.key_global = copy.deepcopy(layer.attention.self.key)\n",
    "            longformer_self_attn_for_codebert.value_global = copy.deepcopy(layer.attention.self.value)\n",
    "            \n",
    "            longformer_model.encoder.layer[i].attention.self = longformer_self_attn_for_codebert\n",
    "        self.model = longformer_model\n",
    "        self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        global_attention_mask = torch.zeros_like(ids)\n",
    "        global_attention_mask[:self.md_max_len] = 0\n",
    "        x = self.model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)[0]\n",
    "        #print(\"fts\", fts)\n",
    "        x = torch.cat((x[:, 0, :], fts), 1)\n",
    "        #print(\"/n\", x.size())\n",
    "        x = self.top(x)\n",
    "        return x\n",
    "        \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=100,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270c06f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.682589Z",
     "iopub.status.busy": "2022-07-05T14:45:08.682002Z",
     "iopub.status.idle": "2022-07-05T14:45:08.905995Z",
     "shell.execute_reply": "2022-07-05T14:45:08.905166Z"
    },
    "papermill": {
     "duration": 0.245108,
     "end_time": "2022-07-05T14:45:08.908188",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.663080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base\"\n",
    "BS = 32\n",
    "NW = 2\n",
    "test_df[\"pct_rank\"] = 0\n",
    "MAX_LEN = 64\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d8e08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:08.947013Z",
     "iopub.status.busy": "2022-07-05T14:45:08.946608Z",
     "iopub.status.idle": "2022-07-05T14:45:09.341051Z",
     "shell.execute_reply": "2022-07-05T14:45:09.340121Z"
    },
    "papermill": {
     "duration": 0.416197,
     "end_time": "2022-07-05T14:45:09.343347",
     "exception": false,
     "start_time": "2022-07-05T14:45:08.927150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8192cdee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:09.383330Z",
     "iopub.status.busy": "2022-07-05T14:45:09.383074Z",
     "iopub.status.idle": "2022-07-05T14:45:09.392584Z",
     "shell.execute_reply": "2022-07-05T14:45:09.390751Z"
    },
    "papermill": {
     "duration": 0.031118,
     "end_time": "2022-07-05T14:45:09.394528",
     "exception": false,
     "start_time": "2022-07-05T14:45:09.363410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 10431,  2741,  ...,   260,  4833,     2],\n",
      "        [    0, 48342, 25980,  ...,   260,  4833,     2],\n",
      "        [    0, 48342, 39154,  ...,   260,  4833,     2],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,  5214,  3631, 10975],\n",
      "        [    0,   170,    40,  ...,  5214,  3631, 10975],\n",
      "        [    0,   170,    67,  ...,  5214,  3631, 10975]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d14db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:09.435310Z",
     "iopub.status.busy": "2022-07-05T14:45:09.434604Z",
     "iopub.status.idle": "2022-07-05T14:45:09.447275Z",
     "shell.execute_reply": "2022-07-05T14:45:09.446485Z"
    },
    "papermill": {
     "duration": 0.034811,
     "end_time": "2022-07-05T14:45:09.449027",
     "exception": false,
     "start_time": "2022-07-05T14:45:09.414216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tqdm(enumerate(tbar)):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    #model.load_state_dict(torch.load(ckpt_path))\n",
    "    state_dict = torch.load(ckpt_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    BS = 32\n",
    "    NW = 2\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    print(model)\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e70c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:09.488821Z",
     "iopub.status.busy": "2022-07-05T14:45:09.488208Z",
     "iopub.status.idle": "2022-07-05T14:45:36.367468Z",
     "shell.execute_reply": "2022-07-05T14:45:36.366458Z"
    },
    "papermill": {
     "duration": 26.903403,
     "end_time": "2022-07-05T14:45:36.371065",
     "exception": false,
     "start_time": "2022-07-05T14:45:09.467662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarkdownModel(\n",
      "  (model): LongformerModel(\n",
      "    (embeddings): LongformerEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): LongformerEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LongformerLayer(\n",
      "          (attention): LongformerAttention(\n",
      "            (self): LongformerSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): LongformerSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LongformerIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LongformerOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): LongformerPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
      ")\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:02,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../input/codebert-base/codebert-base/\"\n",
    "ckpt_path = \"../input/ai4code-models/model-0.bin\"\n",
    "y_test_1 = predict(model_path, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b8a5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:36.424274Z",
     "iopub.status.busy": "2022-07-05T14:45:36.422720Z",
     "iopub.status.idle": "2022-07-05T14:45:36.429724Z",
     "shell.execute_reply": "2022-07-05T14:45:36.428994Z"
    },
    "papermill": {
     "duration": 0.034867,
     "end_time": "2022-07-05T14:45:36.431659",
     "exception": false,
     "start_time": "2022-07-05T14:45:36.396792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24532f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:36.484080Z",
     "iopub.status.busy": "2022-07-05T14:45:36.483376Z",
     "iopub.status.idle": "2022-07-05T14:45:36.500565Z",
     "shell.execute_reply": "2022-07-05T14:45:36.499734Z"
    },
    "papermill": {
     "duration": 0.04563,
     "end_time": "2022-07-05T14:45:36.502665",
     "exception": false,
     "start_time": "2022-07-05T14:45:36.457035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a 8cb8d28a ddfd239c e25aa9bd c6cd22db f9893819 1372ae9b 90ed07ab 39e937ec 7f388a41 ba55e576 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 bbff12d4 aafc3d23 584f6568 80e077ec d3f5c397 8ce62db4 b190ebb4 89b1fdd2 ed415c3c 5115ebe5 322850af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     0a226b6a 8cb8d28a ddfd239c e25aa9bd c6cd22db f9893819 1372ae9b 90ed07ab 39e937ec 7f388a41 ba55e576 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  23607d04 b7578789 bbff12d4 aafc3d23 584f6568 80e077ec d3f5c397 8ce62db4 b190ebb4 89b1fdd2 ed415c3c 5115ebe5 322850af...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80463ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-05T14:45:36.558160Z",
     "iopub.status.busy": "2022-07-05T14:45:36.557536Z",
     "iopub.status.idle": "2022-07-05T14:45:36.564254Z",
     "shell.execute_reply": "2022-07-05T14:45:36.563573Z"
    },
    "papermill": {
     "duration": 0.035341,
     "end_time": "2022-07-05T14:45:36.565972",
     "exception": false,
     "start_time": "2022-07-05T14:45:36.530631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e7a89",
   "metadata": {
    "papermill": {
     "duration": 0.044492,
     "end_time": "2022-07-05T14:45:36.635847",
     "exception": false,
     "start_time": "2022-07-05T14:45:36.591355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.598172,
   "end_time": "2022-07-05T14:45:39.882530",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-05T14:44:50.284358",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
